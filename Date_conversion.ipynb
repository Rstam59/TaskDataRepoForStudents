{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6Nzu5vSHRgN7A+Ct0/oDk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rstam59/TaskDataRepoForStudents/blob/main/Date_conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cKx5XGm4D9H2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "outputId": "8df5022e-dbcb-45c6-8f46-4ff31e61f96e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m10,240\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_9         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m6,144\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m525,312\u001b[0m │ embedding_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m525,312\u001b[0m │ embedding_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
              "│                     │                   │            │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)  │      \u001b[38;5;34m6,168\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,240</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_9         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,144</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
              "│                     │                   │            │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,168</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,073,176\u001b[0m (4.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,073,176</span> (4.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,073,176\u001b[0m (4.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,073,176</span> (4.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5202 - loss: 1.6236 - val_accuracy: 0.7992 - val_loss: 0.5284\n",
            "Epoch 2/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8274 - loss: 0.4557 - val_accuracy: 0.9016 - val_loss: 0.2649\n",
            "Epoch 3/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9182 - loss: 0.2188 - val_accuracy: 0.9606 - val_loss: 0.1330\n",
            "Epoch 4/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9714 - loss: 0.1083 - val_accuracy: 0.9913 - val_loss: 0.0564\n",
            "Epoch 5/5\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0443 - val_accuracy: 0.9977 - val_loss: 0.0242\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78d685b83390>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import date\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, TextVectorization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
        "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "\n",
        "def random_dates(n_dates):\n",
        "    min_date = date(1000, 1, 1).toordinal()\n",
        "    max_date = date(9999, 12, 31).toordinal()\n",
        "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
        "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
        "    x = [MONTHS[d.month - 1] + \" \" + d.strftime(\"%d, %Y\") for d in dates]\n",
        "    y = [d.strftime(\"%Y-%m-%d\") for d in dates]\n",
        "    return x, y\n",
        "\n",
        "np.random.seed(42)\n",
        "x_texts, y_texts = random_dates(10000)\n",
        "\n",
        "# Add \"startofseq\" and \"endofseq\" markers\n",
        "decoder_inputs_texts = [f\"startofseq {text}\" for text in y_texts]\n",
        "decoder_targets_texts = [f\"{text} endofseq\" for text in y_texts]\n",
        "\n",
        "\n",
        "max_input_len = max(len(txt) for txt in x_texts)\n",
        "max_decoder_input_len = max(len(txt) for txt in decoder_inputs_texts)\n",
        "max_decoder_target_len = max(len(txt) for txt in decoder_targets_texts)\n",
        "\n",
        "input_vectorizer = TextVectorization(\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max_input_len,\n",
        "    split='character',\n",
        "    standardize=None\n",
        ")\n",
        "decoder_vectorizer = TextVectorization(\n",
        "    output_mode='int',\n",
        "    output_sequence_length=max(max_decoder_input_len, max_decoder_target_len),\n",
        "    split='character',\n",
        "    standardize=None\n",
        ")\n",
        "\n",
        "# Adapt vectorizers\n",
        "input_vectorizer.adapt(x_texts)\n",
        "decoder_vectorizer.adapt(decoder_inputs_texts + decoder_targets_texts)\n",
        "\n",
        "# Vectorize\n",
        "encoder_input = input_vectorizer(tf.constant(x_texts))\n",
        "decoder_input = decoder_vectorizer(tf.constant(decoder_inputs_texts))\n",
        "decoder_target = decoder_vectorizer(tf.constant(decoder_targets_texts))\n",
        "\n",
        "# Get vocab size\n",
        "input_vocab_size = len(input_vectorizer.get_vocabulary())\n",
        "target_vocab_size = len(decoder_vectorizer.get_vocabulary())\n",
        "\n",
        "# Convert target to one-hot for teacher forcing\n",
        "decoder_target = tf.one_hot(decoder_target, depth=target_vocab_size)\n",
        "\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(None,), name=\"encoder_inputs\")\n",
        "x = Embedding(input_vocab_size, latent_dim, mask_zero=True)(encoder_inputs)\n",
        "encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(x)\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(None,), name=\"decoder_inputs\")\n",
        "x = Embedding(target_vocab_size, latent_dim, mask_zero=True)(decoder_inputs)\n",
        "x = LSTM(latent_dim, return_sequences=True)(x, initial_state=encoder_states)\n",
        "decoder_outputs = Dense(target_vocab_size, activation=\"softmax\")(x)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    [encoder_input, decoder_input],\n",
        "    decoder_target,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    validation_split=0.2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def translate_date(encoder_input_data, decoder_input_data, model, decoder_vectorizer):\n",
        "    \"\"\"\n",
        "    Translates an encoded date input into a human-readable date string.\n",
        "\n",
        "    Args:\n",
        "        encoder_input_data: The encoded input date.\n",
        "        decoder_input_data: The encoded decoder input.\n",
        "        model: The trained seq2seq model.\n",
        "        decoder_vectorizer: The TextVectorization layer used for the decoder.\n",
        "\n",
        "    Returns:\n",
        "        The translated date string.\n",
        "    \"\"\"\n",
        "    # Make prediction\n",
        "    prediction = model.predict([tf.expand_dims(encoder_input_data, axis=0),\n",
        "                                 tf.expand_dims(decoder_input_data, axis=0)])\n",
        "\n",
        "    # Get predicted character indices\n",
        "    predicted_indices = np.argmax(prediction, axis=2)[0]\n",
        "\n",
        "    # Convert indices to characters and join them\n",
        "    translated_text = \"\".join([decoder_vectorizer.get_vocabulary()[index]\n",
        "                                for index in predicted_indices\n",
        "                                if index != 0])\n",
        "\n",
        "    # Remove \"startofseq\" and \"endofseq\"\n",
        "    translated_text = translated_text.replace(\"startofseq \", \"\").replace(\" endofseq\", \"\")\n",
        "\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "QnplzmapTCmz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you want to translate the first sample\n",
        "translated_date = translate_date(encoder_input[0], decoder_input[0], model, decoder_vectorizer)\n",
        "print(translated_date)  # Output: The translated date"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVZwhSJ-TRZ9",
        "outputId": "a419d62c-cb78-49b0-e3e7-3b0b9629f6ba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "7075-09-20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary of the input vectorizer\n",
        "input_vocabulary = input_vectorizer.get_vocabulary()\n",
        "\n",
        "# Get the encoded values for the first sample\n",
        "encoded_date = encoder_input[0].numpy()\n",
        "\n",
        "# Convert encoded values to characters and join them\n",
        "original_date = \"\".join([input_vocabulary[index] for index in encoded_date if index != 0])\n",
        "\n",
        "# Print the original date\n",
        "print(f\"Encoded input: {encoded_date}\")\n",
        "print(f\"Original date: {original_date}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fPnMREUTUjB",
        "outputId": "c45edea7-0e51-440e-ce4f-2e5ac2c55724"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded input: [39  4 29 22  4 23 18  4  7  2  6  8  3  2 10  8 10 15]\n",
            "Original date: September 20, 7075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQKXAxrRT2ai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}